# Основной отчёт

## Сдержимое:  
**Резюме:**   
**Что работает:**   
**Что ещё работает:**   
**Что есть ещё:**   
**Тестируемые модели:**   
**Модель по умолчанию:**   
**Первоначальный план:**   
**Вводные данные:**   
**Встречные проблемы:**   
**Следующая проблема:**   
**Дальнейшие приключения:**   
**Тесты моделей:**   
**Странное:**   
**Вменяемые ответы от модели:**  
**Новые аккаунты:**  

**Что получилось в результате:**   
**Выводы из проделанной работы:**   

---

## Резюме:
Проект окончился не удачно.

Не удалось запустить ленгвистическую модель  
с передачей ей данных из CSV файла,  
не большими блоками.

***Вывод:***  
Полный провал.  

---

### Что работает:
Есть автоматическая загрузка данных  
из ресурса  kaggle.  
Обработка нескольких запросов  
и вывод их через меню в консоль.  
Меню обычное, с указанием выбранного пунтка.  

Что бы попасть в этот режим, нужно:  
После запуска скрипта **ts_kagglehub.py**  
выбрать пункт 3.  
Вы попадаете в диалог с выбором доступных опций.

При первом запуске, скрипт забирает данные из ресурса,  
копирует их в папку ./src/  
и создаёт ещё файл,  
с слайсом в 10 записей.

Что бы забрать файл с данными, через браузер,  
нужна регистрация на ресурсе kaggle.com.  
Если забирать автоматичеси,  
по моему, регистрация не нужна.

---

### Что ещё работает:

При выборе пункта 4  
запустится скрипт **ts_tch_ds.py**  
с моделью, выбранной по умолчанию.  
Этот скрипт, во время тестов,  
единственный выдавал, более или менее понятный результат.

### Что есть ещё:
Есть набор скриптов,  
которые которые использовались для тестов,
в основном результат отрицательный:

- **ts_deepseek.py** -- попытка подключиться к deepseek  
- **ts_kagglehub.py** -- основной скрипт  
- **ts_tch_ds.py** -- скрипт по проще, для библиотеки torch  
.
- **lib_ts.py** -- загрузка данных из kaglehub и меню статистики  
- **lib_model_names.py** -- список тестируемых моделей.  
- **lib_llm__torch.py** -- тест, torch + peft (не удачно)  
- **lib_llm__langch.py** -- тест, langchain (не удачно)  
- **hstory.md** -- содержит историю изменения, занятого моделями места

### Тестируемые модели:
Список тестируемых моделей,  
можно отобразить,  
выбрав пункт **5** из основнго меню.  
Пункт **6** отобразит расширенные данные,  
с результатами тестов  
(в основном, описаине ошибки, полжившей причиной для отказа).  
Пункт **7** выведет расширенные данные,  
по моделям, которые хоть как то запускались.

### Модель по умолчанию:
Модель по умолчанию,  
указана в файле: **lib_model_names.py**  
в строке 19  
для параметра *defmodel*

В строке 3 параметр *defmodel*  
содержит количество библиотек,  
для перебора в списках.

---

### Первоначальный план:
Изначальн планировалось,  
скачать рскоязычную модель,  
отдать ей блок данных из файла,  
протестировать запрос на генерацию статистики  
из переданных данных.

### Вводные данные:
Нужно учесть,  
что данная задача новая.  
Ранее, с большими лингвистическими моделями,  
ни где не пересекался  
и опыта работы с ними, небыло совсем.

К этому нужно добавить,  
что машина, на которой проходили тесты,  
весьма ограничена в ресурсах,
не позволяющих полноценную обработку llm.

### Встречные проблемы:
При поптыке загрузить библиотеку torch  
она не поместилась на доступном месте.  
Пришлось переместить проект на другой диск.  
При следующей попытке, не хватило места  
для временных файлов pip,  
пришлось переназначить путь к временным файлам для pip.  
При попытке загрузить первую модель, ситуация повторилась:  
Результативный размер модели, оказался примерно в 27 гигабайт.  
Что бы его загрузить,  
пришлось переместить папку для моделей  
загружаемых из ресурса huggingface.co

При последующих загрузках,
общий объём моделей,  
доходил до более чем 55 гигабайт.  
В последствии, часть удалял.

Была попытка загрузить модель на сервере.  
Скорость была высокой,  
но загрузка отменялась,  
при достижение объёма кеша,  
ровно в 280 метров.  
В тонкостях этой проблемы, разбираться не стал.

#### Следующая проблема:  
Оказалось, что для обработки моделей, 
нужны кудаядра и мощьная видеокарта.  
Версия драйверов куда ядер, устаревшая  
и обновить их, в данный момент нельзя.  
Решение: переключил обработку на CPU.

#### Дальнейшие приключения:  
Далее оказалось,  
что не все библиотеки,  
могут обрабатываться кодом из примера  
взятого с хабра.  
Даже библиотека в примере,  
не запустилась.  
(Как я подумал изначально  
По факту, ей нужно было больше времени,  
чем у меня было терпения.)

В статье было 2 примера,  
один просто диалог,  
второй с подгрузкой данных из .doc файла.  
По факту, ни один из них, у меня не работал.

Тесты некоторых моделей, требовали ключ open_ai_key  
получить который не возможно,  
ввиду блокировки доступа из россии.  
Для подключения к своему апи,  
этот ключ требовли deepseek, langchain.smith  
а также некоторые модели, при попытке их хапуска  
уже после загрузки.  
(или перед, уже запутался.)  

#### Тесты моделей:
Было опробовано 17 моделей.  
Часть из них не запустились совсем.  
Часть были огромными и загрузку отменял.  
Не большие библиотеки запускались, но:  
или работали не с текстовым форматом.

#### Странное:
Одну крупную модель загрузил дважды.  
Первый раз удалил, посчитав, что она не рабочая.  
Второй раз тестил до отказа.  
В результате, она давала осмысленный результат.  
Но до загрузки данных, дело не дошло.  
После первого успешного запуска, с ответом,  
модель исчезла из папки загруженных моделей.  
Куда она делась, так и не нашёл.  
Но судя по занятому проектом на диске месту,  
она должна лежать, где то рядом.  
Но где конкретно, осталось загадкой.

### Вменяемые ответы от модели:
Простая фраза "Привет.", обрабатывалась почти час.  
Чуть сложнее,   
с просьбой рассказать о себе,  
почти 3 часа.  
Более конкретный вопрос,   
с вопросом, как работать с моделью,  
занял почти 5 часов.

Подключать к ней данные не стал,  
это будет очень долго.  
В условиях ограниченого времени,  
это задачу, в текущей ситуации, выполнить не реально.

С сдачей тз и так затянул.  
Разбираться как загружать данные  
и тестировать это,  
нет времени.

### Новые аккаунты:
В процессе выполнения,  
понадобилось зарегистрироваться,  
для получения данных или ключей,  
на следующих ресурсах:  
**kagle.com**  
**platform.deepseek.com**  
**smith.langchain.com**  

---
## Что получилось в результате:
По факту вполнения тз,  
с основной задчей не справился:  
Не были загружены данные в llm,  
не были протестированы запросы,  
для получения статистики из загруженных данных.  
Время выполнения, было растянуто  
более чем на неделю.  

***Вывод:***  
Основаная задача не выполнена.  
Совсем.

---
## Выводы из проделанной работы:
Не смотря на отрицательный результат,  
работа над тз, оказала положительное влияние.  
Были изучены некоторые возможности, по работае с LLM,  
получено общее представление,  
чего ожидать, при работе с ними.  
Стало понятно, каким может быть поведение скрипта,  
при попытке работы, с не знакомыми моделями.  
В целом, в следующий раз,  
когда понадобится знаматься лингвистическими моделями ИИ,  
уже буду знать, от чего отталкиваться.  
Не с нуля.  

Как результат:  
Очень благодарен,  
за возможность выполнить,  
интересное задание.  
И за возможность расширить кругозор,  
в очень полезном и перспективном направлении.  
Спасибо.  
